{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with Naive Bayes - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, you'll practice implementing the Naive Bayes algorithm on your own.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will:  \n",
    "\n",
    "* Implement document classification using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset\n",
    "\n",
    "To start, import the dataset stored in the text file `'SMSSpamCollection'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# read in data with delimiter tab\n",
    "data = pd.read_csv('SMSSpamCollection', delimiter = '\\t', header = None,\n",
    "                  names = ['label', 'text'])\n",
    "\n",
    "# inspect first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for class imbalance\n",
    "\n",
    "To help your algorithm perform more accurately, subset the dataset so that the two classes are of equal size. To do this, keep all of the instances of the minority class (spam) and subset examples of the majority class (ham) to an equal number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "# how many instances of each?\n",
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thank god they are in bed!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>ham</td>\n",
       "      <td>&amp;lt;#&amp;gt; %of pple marry with their lovers... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm not coming over, do whatever you want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh right, ok. I'll make sure that i do loads o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>ham</td>\n",
       "      <td>What's the significance?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8     spam  WINNER!! As a valued network customer you have...\n",
       "9     spam  Had your mobile 11 months or more? U R entitle...\n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "...    ...                                                ...\n",
       "2637   ham                         Thank god they are in bed!\n",
       "1360   ham  &lt;#&gt; %of pple marry with their lovers... ...\n",
       "1774   ham          I'm not coming over, do whatever you want\n",
       "2828   ham  Oh right, ok. I'll make sure that i do loads o...\n",
       "509    ham                           What's the significance?\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# get spam data\n",
    "spam_data = data[ data.label == 'spam' ]\n",
    "\n",
    "# get ham data\n",
    "ham_data = data[ data.label == 'ham' ]\n",
    "\n",
    "# select a random sample of indices from ham_data, as many as are in spam_data\n",
    "ham_indices = np.random.choice(ham_data.index, size = len(spam_data), replace = False)\n",
    "\n",
    "# subset ham_data\n",
    "ham_data = ham_data.loc[ham_indices, :]\n",
    "\n",
    "# put data back together\n",
    "subset_data = pd.concat([spam_data, ham_data], axis = 0)\n",
    "\n",
    "subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    747\n",
       "ham     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of each, spam and ham\n",
    "subset_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't think it matters, but I would like the rows to be back in order by index\n",
    "subset_data.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "Now implement a train-test split on the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = subset_data['text']\n",
    "y = subset_data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 2, test_size = 0.25)\n",
    "train_df = pd.concat([X_train, y_train], axis = 1)\n",
    "test_df = pd.concat([X_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word frequency dictionary for each class\n",
    "\n",
    "Create a word frequency dictionary for each class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# for each unique label, count words that show up in rows with that label\n",
    "\n",
    "# get classes by selecting unique elements in the label column of the training set\n",
    "classes = np.unique(train_df.label)\n",
    "\n",
    "# create an empty dictionary to hold a dictionary of word counts for each label\n",
    "class_word_freq = {}\n",
    "\n",
    "for label in classes:\n",
    "    # create a bag to hold frequencies of words for this label\n",
    "    bag = {}\n",
    "    \n",
    "    # find records in training set with this label\n",
    "    records = train_df[ train_df.label == label ]\n",
    "    \n",
    "    # loop over each record with this label\n",
    "    for row in records.index:\n",
    "        \n",
    "        # get the text for that record\n",
    "        doc = train_df.loc[row, 'text']\n",
    "        \n",
    "        # split the text by word\n",
    "        for word in doc.split():\n",
    "            \n",
    "            # add this word to the bag, or increment its count if already added\n",
    "            bag[word] = bag.get(word, 0) + 1\n",
    "            \n",
    "    # after looping over all records, save this bag to this class in class_word_freq\n",
    "    class_word_freq[label] = bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the total corpus words\n",
    "Calculate V, the total number of words in the corpus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5935"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# create an empty set\n",
    "vocab = set()\n",
    "\n",
    "# add each word in the 'text' section of the data frame to the vocabulary set\n",
    "\n",
    "# iterate over all records in training set\n",
    "for record in train_df.index:\n",
    "    doc = train_df.loc[record, 'text']\n",
    "    \n",
    "    # split into words; add each one to vocab set\n",
    "    for word in doc.split():\n",
    "        vocab.add(word)\n",
    "\n",
    "# find the length of the vocabulary set\n",
    "total_corpus_words = len(vocab)\n",
    "\n",
    "total_corpus_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bag of words function\n",
    "\n",
    "Before implementing the entire Naive Bayes algorithm, create a helper function `bag_it()` to create a bag of words representation from a document's text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def bag_it(doc):\n",
    "    # define an empty bag\n",
    "    bag = {}\n",
    "    \n",
    "    # break document into words; add word to bag, or increment its count if already added\n",
    "    for word in doc.split():\n",
    "        bag[word] = bag.get(word, 0) + 1\n",
    "        \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes\n",
    "\n",
    "Now, implement a master function to build a naive Bayes classifier. Be sure to use the logarithmic probabilities to avoid underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def classify_doc(doc, class_word_freq, p_classes, V, return_posteriors=False):  \n",
    "    # ultimately, based on posteriors, return class\n",
    "    classes = []\n",
    "    posteriors = []\n",
    "    \n",
    "    # iterate over each class\n",
    "    for label in class_word_freq.keys():\n",
    "        \n",
    "        # get probability of that class overall as base probability\n",
    "        p = np.log(p_classes[label]) # take log of probability to avoid tiny # rounding error\n",
    "        \n",
    "        # for each word in this doc:\n",
    "        # multiply p by the ratio (word count in this doc + 1) / (word count in class i + total\n",
    "        # number of unique words in the entire corpus)\n",
    "        # but make it a log probability, so add log(num / denom) successively to p\n",
    "        \n",
    "        # get a bag of words for this doc\n",
    "        bag = bag_it(doc)\n",
    "        \n",
    "        for word in bag:\n",
    "            numerator = bag[word] + 1\n",
    "            denominator = class_word_freq[label].get(word, 0) + V\n",
    "            p += np.log(numerator / denominator)\n",
    "        \n",
    "        classes.append(label)\n",
    "        posteriors.append(p)\n",
    "    \n",
    "    if return_posteriors:\n",
    "        return classes[np.argmax(posteriors)], posteriors\n",
    "    else:\n",
    "        return classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your classifier\n",
    "\n",
    "Finally, test your classifier and measure its accuracy. Don't be perturbed if your results are sub-par; industry use cases would require substantial additional preprocessing before implementing the algorithm in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability of ham and spam independently (should be 50 / 50 because of the way we\n",
    "# constructed the subset of the original data)\n",
    "\n",
    "p_classes = train_df.label.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# for each record in the training set\n",
    "# pass in the text for that record as doc\n",
    "# pass in class_word_freq, p_classes, total_corpus_words, return_posteriors = True\n",
    "# store predictions as y_hat preds\n",
    "\n",
    "y_preds = [classify_doc(X_train.loc[i], class_word_freq, p_classes,\n",
    "                        total_corpus_words) for i in X_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.772321\n",
       "True     0.227679\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check accuracy\n",
    "residuals = y_train == y_preds\n",
    "residuals.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)\n",
    "\n",
    "Rework your code into an appropriate class structure so that you could easily implement the algorithm on any given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab, you practiced implementing Naive Bayes for document classification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
